\documentclass[10pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb, cancel, xcolor, mathtools}

\newcommand\hcancel[2][black]{\setbox0=\hbox{$#2$}%
\rlap{\raisebox{.45\ht0}{\textcolor{#1}{\rule{\wd0}{1pt}}}}#2} 

\begin{document}

\begin{flushleft}
    Brandon Szeto \\
    Professor Kenneth Zeger \\
	ECE 109 \\
\end{flushleft}

\begin{center}
	\Large \textbf{Week 3, Lecture 01-24-23}
\end{center}
\normalsize

\begin{flushleft}

\begin{itemize}
    \item[\textbf{\underline{Example:}}] \textbf{Flip a coin twice}
        $$ S = \{HH, HT, TH, TT\} $$
        Let us define the events:
        $$ \begin{aligned}
            E &= \text{"First flip is heads"} = \{HH, HT\} \\
            F &= \text{"Flips are different"} = \{HT, TH\} \\
        \end{aligned} $$
        $$ \begin{aligned}
            P(E) &= \frac{2}{4} = \frac{1}{2} \\
            P(E|F) &= \frac{P(EF)}{P(F)} = \frac{P(\{HT\})}{P(\{HT, TH\})} \\
                   &= \frac{\frac{1}{4}}{\frac{2}{4}} = \frac{1}{2}
        \end{aligned} $$
        So, in this case,
        $$ \begin{aligned}
            P(E) &= P(E|F) = \frac{1}{2} \\
                 &\rightarrow E, F \text{ are independent} 
        \end{aligned} $$
        Let's multiply both sides by $P(F)$:
        $$ P(E)P(F) = P(E|F)P(F) = P(EF) $$
        i.e. $P(EF)$ factors into $P(E)P(F)$. If $P(F) \neq 0$, then this implies $P(E|F) = P(E)$.
\end{itemize}
        $$\boxed{ \text{\textbf{Definition:} Events } E, F \text{ are independent
            if }
        P(EF) = P(E)P(F). }$$
        \textbf{Consequences:} If $E,F$ are independent, then
        \begin{enumerate}
            \item $E, F^c$ are independent
            \item $E^c, F$ are independent
            \item $E^c, F^c$ are independent
        \end{enumerate}
        \textbf{Proof of 1:} Assume $P(E) \neq 0$.
        $$ \begin{aligned} 
            P(EF^c) &= P(E)P(F^c|E) \\
                    &= P(E)(1 - P(F|E)) \\
                    &= P(E)(1 - P(F)) \\
                    &= P(E)P(F^c) \\
                    &\rightarrow E, F^c \text{ are independent}
        \end{aligned}$$

        \begin{center}
            \textbf{Disjoint versus Independence}
        \end{center}
        Suppose $E, F$ are disjoint and $P(E) \neq 0$ and $P(F) \neq 0$.
        $$ \therefore EF = 0 $$
        $$ \begin{aligned}
            P(EF) &= P(0) = 0 \\
            P(E)P(F) &\neq 0
        \end{aligned} $$
        $$ \therefore P(EF) \neq P(E)P(F) $$
        $$ \rightarrow P(E) \neq 0 \text{ but } P(E|F) = 0$$.

        \newpage

\begin{itemize}
    \item[\textbf{\underline{Example:}}] \textbf{Given two inputs x and y, the
        output of an XOR gate z is 1 if and only if $x \neq y$}
        $$ x, y, z \in \{0, 1\} $$
        Suppose x and y are chosen with equal probability $\frac{1}{2}$ and
        independently. Let us define the events:
        $$ \begin{aligned}
            A &== x = 1 \\
            B &== y = 1 \\
            C &== z = 1 \\
        \end{aligned} $$
        By assumption $A, B$ are independent events.
        $$ \begin{aligned}
            P(A) = P(B) &= \frac{1}{2} \\
            C &= AB^c \cup A^cB \\
            P(C) &= P(AB^c \cup A^cB) \\
                 &= P(AB^c) + P(A^cB) \\
                 &= P(A)P(B^c) + P(A^c)P(B) \\
                 &= \frac{1}{2} * \frac{1}{2} + \frac{1}{2} * \frac{1}{2} \\
            AC &== x = 1 \text{ and } z = 1 \\
               &== x = 1, y = 0, z = 1 \\
               &== x = 1, y = 0 \\
               &== AB^c \\
            P(AC) &= P(AB^c) = P(A)P(B^c) = \frac{1}{2} * \frac{1}{2} =
            \frac{1}{4} \\
            \therefore P(AC) &= P(A)P(C) \\
                             &\rightarrow A, C \text{ are independent}
        \end{aligned} $$
        Also by symmetry, $B, C$ are independent. But $A, C$ (also $B, C$) are
        \textbf{not} physically indepent. It is very clear that they are part of the
        same XOR gate.
\end{itemize}

$$ \boxed{ \begin{aligned}
        \text{\textbf{Definition:} Events } A, B, &C \text{ are \textbf{independent}
if all of the following are true:}  \\
        1) \text{ } &A, B \text{ are independent} \\
        2) \text{ } &B, C \text{ are independent} \\
    3) \text{ } &A, C \text{ are independent} \\
    4) \text{ } &P(ABC) = P(A)P(B)P(C)
\end{aligned} }$$
\textbf{Note:} If $A,B,C$ are pairwise independent, then
$$ P(ABC) = P(A)P(B)P(C) $$
is equivalent to $P(A|BC) = P(A)$ since:
$$ \begin{aligned}
    P(A|BC)P(BC) &= P(A)P(BC) \\
    P(ABC) &= P(A)P(B)P(C)
\end{aligned} $$
It is possible to satisfy pairwise independence (conditions numbers 1, 2, and
3), but not condition number 4. Consider the XOR example.
$$ \begin{aligned}
    ABC &== x = 1, y = 1, z = 1 = 0 \\
    P(ABC) &= P(0) = 0 \\
\end{aligned} $$
But $P(A)P(B)P(C) = \frac{1}{2} * \frac{1}{2} * \frac{1}{2} = \frac{1}{8} \neq
0$\\
$$ \therefore \text{ condition number 4 is not satisfied.}$$
$$ \therefore A, B, C \text{ are pairwise independent but } A, B, C \text{ are
\textbf{not} independent} $$

$$ \boxed{ \begin{aligned}
        \text{\textbf{Definition:} Events A, B are} &\text{ \textbf{conditionally
    independent given event C}, if:} \\
                                                    &P(AB|C) = P(A|C)P(B|C) \\
                                                    &\text{assuming  } P(C) \neq 0 \\
\end{aligned}} $$

\textbf{Note:} If $A, B$ are independent given $C$, then:
$$ \begin{aligned}
    P(A|BC) = \frac{P(ABC)}{P(BC)} &= \frac{P(AB|C)P(C)}{P(B|C)P(C)} \\
                                   &= P(A|C)
\end{aligned}$$
This is similar to $P(A|B) = P(A)$ but with the extra "given C".

\begin{itemize}
    \item[\textbf{\underline{Example:}}] \textbf{Flip 2 coins} \\
        Let us define the events:
        $$ \begin{aligned}
            A &= \text{"First coin is heads"} \\
            B &= \text{"Second coin is heads"} \\
            C &= \text{"First and second coin are both heads"} \\
        \end{aligned} $$
        Note: $C = AB$
        \begin{enumerate}
            \item $A, B$ are independent (by assumption)
            \item $ \begin{aligned}
                    P(A|C) &= \frac{P(AC)}{P(C)} = \frac{P(AAB)}{P(C)} = \frac{P(AB)}{P(C)} =
                    \frac{P(C)}{P(C)} = 1 \\
                    P(A|BC) &= \frac{P(ABC)}{P(BC)} = \frac{P(C)}{P(C)} = 1 \\
                    \therefore P(A|C) &= P(A|BC) = 1 \\
                                      &\rightarrow A, B \text{ are independent given } C.
                \end{aligned} $
            \item $ \begin{aligned}
                    P(A|C^c) &= \frac{P(AC^c)}{P(C^c)} = \frac{P(HT)}{1 - P(HH)}
                    = \frac{\frac{1}{4}}{1 - \frac{1}{4}} = \frac{1}{3}
                    \frac{P(C)}{P(C)} = 1 \\
                    P(A|BC^c) &= \frac{P(ABC^c)}{P(BC^c)} = \frac{P(0)}{P(TH)} =
                    0\\
                    \therefore P(A|C^c) &\neq P(A|BC^c) \\
                                        &\rightarrow A, B \text{ are
                                        \textbf{not} independent given } C^c.
                \end{aligned} $
        \end{enumerate}
    \item[\textbf{\underline{Example:}}] \textbf{Let a sample space of
            equiprobable outcomes be:} \\
            $$ S = \{ 1, 2, 3, 4, 5 \} $$
            Let us define the events:
        $$ \begin{aligned}
            A &= \{1, 2, 5\} \\
            B &= \{1, 3, 5\} \\
            C &= \{1, 2, 3, 4\} \\
        \end{aligned} $$
        \begin{enumerate}
            \item We know $P(A)$ and $P(B)$ are not independent from the
                following: $$ \begin{aligned}
                    P(AB) &= P(\{1, 5\}) = \frac{2}{5} \\
                    P(A) &= P(B) = \frac{3}{5} \\
                    P(AB) &\neq P(A)P(B) \\
                          &\rightarrow A, B \text{ \textbf{not} independent}
                \end{aligned} $$
            \item However, given $C$, this changes $ \begin{aligned}
                    P(AB|C) &= P(\{1,5\}|\{1,2,3,4\}) = \frac{1}{4} \\
                    P(A|C) &= P(\{1,2,5\}|\{1,2,3,4\}) = \frac{2}{4} =
                    \frac{1}{2} \\
                    P(B|C) &= P(\{1,3,5\}|\{1,2,3,4\}) = \frac{2}{4} =
                    \frac{1}{2} \\
                    \therefore P(AB|C) &= P(A|C) * P(B|C) \\
                                       &\rightarrow A, B \text{ are independent
                                       given }
                                       C.
                \end{aligned} $
        \end{enumerate}
\end{itemize}

\newpage

\begin{center}
	\Large \textbf{Week 3, Lecture 01-26-23}
\end{center}

\begin{itemize}
    \item[\textbf{\underline{Example:}}] \textbf{Experiment: Flip 3 coins.
        Define event E = "exactly one head". What is the probability event E
    occurs exactly k times in n trials?} \\
    This can be thought of as $E$ occuring $k$ times and $E^c$ occurring $n - k$
    times.
    $$ \begin{aligned}
        = (P(E))^k * (P(E^c))^{n-k} \\
        = (P(E))^k * (1 - P(E))^{n-k} \\
    \end{aligned}$$
    There are $\binom{n}{k}$ arrangements of where the $k$ occurrences of $E$
    could be, so the total probability is 
    $$ \binom{n}{k} (P(E))^k * (1 - P(E))^{n-k} $$

\item[\textbf{\underline{Example:}}] \textbf{Now we use three biased coins.}
    $$ \begin{aligned}
        E &=  \text{exactly one head occurs} \\
        P(E) &= P(\{HTT, THT, TTH\}) \\
             &= 3q(1 - q)^2
    \end{aligned}$$
    \textbf{P(E occurs 4 times in 10 trials)} \\
    (i.e. when k = 4, n = 10)
    $$ \binom{10}{4}(3q(1-q)^2)^4(1-3q(1-q)^2)^{10 - 4}$$

\item[\textbf{\underline{Example:}}] \textbf{Suppose A, B are events in an
    experiment and are disjoint. What is the probability A occurs before B in
independent trials?} \\
    This can happen in these ways:
    $$ \begin{aligned}
        &C = (A \cup B)^c = \text{neither} \\
        &A \\
        &C, A \\
        &C, C, A \\
        &C, C, C, ..., A \\
    \end{aligned} $$
    The net probability is 
    $$ \begin{aligned}
        &P(A) + P(C)P(A) = (P(C))^2P(A) + (P(C))^3P(A) + ...  \\
        &= P(A)(1 + P(C) + P(C)^2 + P(C)^3 + ... ) \\
        &= P(A)\left( \frac{1}{1 - P(C)} \right) = \frac{P(A)}{P(A) + P(B)}
    \end{aligned}$$

\item[\textbf{\underline{Example:}}] \textbf{3 coin flips (fair coins)}
    Define:
    $$ \begin{aligned}
        A &= \text{3 heads} \\
        B &= \text{1 head} \\
    \end{aligned} $$
    Therefore, P(exactly 3 heads before exactly 1 head):
    $$ \frac{P(A)}{P(A) + P(B)} = \frac{\frac{1}{8}}{\frac{1}{8} + \frac{3}{8}}
    = \frac{1}{4} $$
\item[\textbf{\underline{Example:}}] \textbf{Flip biased coin (q = P(H))
    repeatedly until we get at least 10 heads, then stop. What is the
probability we flip the coin exactly 15 times?} \\
This situation occurs when we flip heads after having flipped 9 heads and 5
tails in any order for a total of 14 flips. Therefore the probability can be
found by
$$ \binom{14}{5}q^9(1 - q)^5 * q $$

\item[\textbf{\underline{Example:}}] \textbf{Flip the biased coin until we get
    at least 3 heads and 5 tails. What is the probability we flip the coin
exactly 20 times?} \\
This situation can occur in two ways: when we flip heads after having flipped 2
heads and 17 tails, or when we flips tails after having flipped 4 tails and 15
heads. Therefore, the probability can be found by
$$ \binom{19}{2}q^2(1 - q)^{17} * q + \binom{19}{4}q^{15}(1 - q)^4 * (1 - q) $$
\end{itemize}

$$\boxed{ \text{\textbf{Definition:} A random variable for a sample space } S
    \text{ is a mapping }
X: S \rightarrow \mathbb{R}}$$
In other words, for  each $u \in S$, $X(u)$ is a real number.

\begin{itemize}
    \item[\textbf{\underline{Example:}}] \textbf{S = \{apple, banana, orange\}}
        \\
        Let
        $$ \begin{aligned}
            &X(\text{apple}) = 3 \\
            &X(\text{banana}) = -\pi \\
            &X(\text{orange}) = 0 \\
        \end{aligned} $$
        Let
        $$ \begin{aligned}
            &Y(\text{apple}) = 5 \\
            &Y(\text{banana}) = 6 \\
            &Y(\text{orange}) = 6 \\
        \end{aligned} $$
        X, Y are random variables. This can be abbreviated as r.v.

    \item[\textbf{\underline{Example:}}] \textbf{Flip 3 coins (fair) Define r.v.
        X as follows:} \\
        X counts the number of heads.
        $$ \begin{aligned}
            X(HHH) &= 3 \\
            X(HTH) &= X(THH) = X(HHT) = 2\\
            X(HTT) &= X(THT) = X(TTH) = 1\\
            X(TTT) &= 0 \\
        \end{aligned} $$
        Define the r.v. Y as follows:
        $$ \begin{aligned}
            Y(HHH) &= 1 \\
            Y(u) &= 0 \text{ if } u \neq HHH\\
        \end{aligned} $$
        Convention to use upper case letters for random variables. The above
        information can be used to find the following probabilities:
        $$ \begin{aligned}
            P( X = 2 ) &= \frac{3}{8} \\
            P( X \leq 2 ) &= \frac{7}{8} \\
            P( Y < \frac{1}{2} ) &= \frac{7}{8} \\
            P( X = Y ) &= \frac{1}{8} \\
            P( X > Y ) &= \frac{7}{8} \\
        \end{aligned}$$
        What does $P(X = 2)$ actually mean? It means the probability of the
        event
        $$ \{ u \in S : X(u) = 2 \}$$
        $$ = \{ HHT, HTH, THH \} $$
        The notation "x = 2" means the above event.
        Similarly,
        $$ \begin{aligned}
            X \leq 2 &= \{ u \in S : X(u) \leq 2 \} \\
            X = Y &= \{ u \in S : X(u) = Y(u) \}
        \end{aligned}$$
        Random variables are not random. Inputs are random and thus outputs are
        random.

\end{itemize}

$$\boxed{ \text{\textbf{Cummulative Distribution Function (CDF)} of a random
variable X is } F_x(u) = P(x \leq u) }$$

\end{flushleft}

\end{document}
